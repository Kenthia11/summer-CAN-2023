{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e2913bf",
   "metadata": {},
   "source": [
    "# <center>  Working With Dataframes </center>\n",
    "<div>\n",
    "<img src=\"https://pandas.pydata.org/static/img/pandas.svg\" width=\"600\"/>\n",
    "</div>\n",
    "\n",
    "In the last lecture, we were introduced to the `pandas` library, which gives us the ability to work with two new data types: dataframes and series. In this lecture, we will learn more about how to use and work with dataframes.\n",
    "\n",
    "We're going to talk about some ways to handle and work with dataframes, which includes basic selection and deletion of columns, renaming columns, etc. Then, we'll go a bit into subsetting data using various selection methods. Finally, we talk about some methods for dataframes that will be useful for data organization, manipulation and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9add184c",
   "metadata": {},
   "source": [
    "## Handling Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f16662",
   "metadata": {},
   "source": [
    "To learn how to use dataframes to their fullest capacity, we first need to know how to handle them. First, let's import pandas and numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7195d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f171ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sales = pd.read_csv('../datasets/sales.csv')\n",
    "sales.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40835d6a",
   "metadata": {},
   "source": [
    "This is a dataset of sales from a retail store over 4 years. At a quick glance, we can see the type of data collected. We have some IDs in the form of alphanumerical data, some dates, names, locations, etc.\n",
    "\n",
    "In getting acquainted with our data, we may want to quickly know how many entries there are and how many attributes are measured per entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0ed1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sales.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d23e12",
   "metadata": {},
   "source": [
    "Recall that dataframes are made of concatanated series in the form of columns. To extract one column from a dataframe, we call for the dataframe and then close the name of the column (as a string) in single square brackets or double square brackets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c09c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Segment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7b4470",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[['Segment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7e4c63",
   "metadata": {},
   "source": [
    "**What do notice about the difference in extracting a column with single square brackets versus double square brackets?**\n",
    "\n",
    "Notice that using single square brackets returns a series, while the use of double square brackets return a one-column dataframe. This is important, as it can dictate how the output can be used, as well as what functions and methods can be used on it.\n",
    "\n",
    "For example, if we wanted to get the first item of the `Segment` column, we could use `sales['Segment'][0]` with a series, but not with a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445165b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Segment'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e95188a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales[['Segment']][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddb4b25",
   "metadata": {},
   "source": [
    "However, if you wanted to select multiple columns at once, that can be done with a dataframe, but not a series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a50cf18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales[['Segment', 'Ship Mode']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a36a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Segment', 'Ship Mode']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7092f3f9",
   "metadata": {},
   "source": [
    "We can also extract a dataframe column by using a `dataframe.column_name` notation. This is best to use when there are no spaces in the column name. A series will be returned by using this notation, similar to `dataframe['column_name']`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beeff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.Segment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b2505b",
   "metadata": {},
   "source": [
    "It is also useful to rename columns in a dataframe using the `.rename()` method. Calling this method on a dataframe, you can easily rename a column by passing a dictionary with the keys being the current column name and the values being the desired column name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88e15d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales = sales.rename(columns={'Postal Code':'Zip Code', 'Ship Mode':'Shipping Method'})\n",
    "sales.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a71568",
   "metadata": {},
   "source": [
    "New columns can be added to dataframes as well. If you wish to add a column based on other columns that already exist in the dataframe, you can perform operations on the columns and assign them to the new desired column. Here, we make a new column called `Full Location` that combines data from the `City` and `State` columns, separated by a comma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd01a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Full Location'] = sales['City'] + ', ' + sales['State']\n",
    "sales.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71009a94",
   "metadata": {},
   "source": [
    "If desired, you can also create an empty column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963af603",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Empty'] = \"\"\n",
    "sales.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e78d8fd",
   "metadata": {},
   "source": [
    "There may be times where you want to delete columns. This can be accomplished using the `.drop()` method. When you call this method on a dataframe, you can pass a single column name or a list of column names to the `columns` parameter. The `inplace=True` parameter updates the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857ec09c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sales.drop(columns=['Country', 'Empty'], inplace=True)\n",
    "sales.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811dc324",
   "metadata": {},
   "source": [
    "Notice that we utilized two ways of updating dataframes using these methods. One way was to use the method on the dataframe and reassign the output of that to the name of the dataframe (as we did when using the `.rename()` method).The other way was by specifying the `inplace` parameter as `True` (as we did with the `.drop()` method). \n",
    "\n",
    "Both of these ways are fine, but be mindful that not all methods and functions have an `inplace` parameter. Therefore, it's always a good idea to refer to the documentation of a function or method to understand how it can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bf6948",
   "metadata": {},
   "source": [
    "## Subsetting data in dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bb1727",
   "metadata": {},
   "source": [
    "Being able to parse and subset data intentionally is important for downstream data analysis. When consecutive rows of data need to be extracted, dataframes can be sliced similar to lists and arrays. To extract the first 50 rows of `sales` we could slice the dataframe as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72246f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "top50 = sales[0:50]\n",
    "print('Number of rows in top50:', len(top50))\n",
    "top50.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16396032",
   "metadata": {},
   "source": [
    "Likewise we can extract intervals of rows using double colons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1037ef4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "even_rows = sales[0::2]\n",
    "print('Selecting every other column gives us a dataframe of', len(even_rows), 'rows.')\n",
    "\n",
    "even_rows.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa23b44",
   "metadata": {},
   "source": [
    "To exact all rows and a specific column, we can use the `.iloc[]` method. The `.iloc[]` method uses integer-location based indexing for selection of rows and columns by position. To select all rows and the `Ship Date` column (which has an index of 3), we can type the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507f44e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales.iloc[:, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e117a8",
   "metadata": {},
   "source": [
    "Vice versa, we can select the data corresponding to all columns of the fourth row (which has an index of 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade072a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales.iloc[3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6236505d",
   "metadata": {},
   "source": [
    "Using `.iloc[]` we can specifically select cells of a dataframe by inputting its row and column index values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9feba4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales.iloc[234, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e36b56",
   "metadata": {},
   "source": [
    "Similar to slicing, we can also select specific indexes or a range of consecutive indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd938da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.iloc[0:500, [3,6,12]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2ce1a0",
   "metadata": {},
   "source": [
    "**What do you think this code does? Discuss with your neighbor for approximately one minute.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c33a656",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rows = np.arange(45,107, step = 5)\n",
    "\n",
    "sales.iloc[rows, 13:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c780d6b",
   "metadata": {},
   "source": [
    "**What do you think this does? Discuss with your neighbor for approximately one minute.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced2731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.iloc[2999:3872:100, 4::3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5382a2b0",
   "metadata": {},
   "source": [
    "Another way to extract data from dataframes is using the `.loc[]` method. The `.loc[]` method utilizes labels or boolean arrays to select data. While specifying the indices of a list of rows you wish to select, you can utilize the name of a column to extract data of interest, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883c6f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.loc[[22,485,1008], \"Category\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec7ed71",
   "metadata": {},
   "source": [
    "Moreover, you can select multiple columns by passing a list into the `.loc[]` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63278288",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.loc[[22,485,1008], [\"Category\", \"Sub-Category\", \"Shipping Method\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cca9e59",
   "metadata": {},
   "source": [
    "The `.loc[]` method is a really powerful selection method that can be used to extract data based on conditions. Here, we select all rows where the `Region` column equates to `West`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeaf4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "west = sales.loc[(sales['Region'] == 'West')]\n",
    "west.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9f0352",
   "metadata": {},
   "source": [
    "We can also compound conditions using bitwise operators. We can select rows that meet one of multiple conditions by using the `|` operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce6fb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_florida = sales.loc[(sales['Region'] == 'West') | (sales['State'] == 'Florida')]\n",
    "w_florida.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a47d0",
   "metadata": {},
   "source": [
    "If we want rows that meet <u>all</u> of our conditions of interests, we can use the `&` operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9d26d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_low = sales.loc[(sales['State'] == 'New York') & (sales['Sales'] < 100)]\n",
    "ny_low.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f4145b",
   "metadata": {},
   "source": [
    "As shown before, we don't have to return all columns of the dataframe when selecting based on condition. We can return only the columns of interest by passing the names of these columns as a list into the `.loc[]` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aa6855",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvh = sales.loc[(sales['Customer Name'] == 'Darrin Van Huff'), ['Order Date', 'Customer Name', 'Category']]\n",
    "dvh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a47128",
   "metadata": {},
   "source": [
    "Using a combination of index-based and label-based location, the `.loc[]` method also allows us to select specific cells of interest. By doing so, we can change data in our dataframe as needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2c8c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.loc[0, ['Ship Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2543eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.loc[0, ['Ship Date']] = '11/13/2017'\n",
    "sales.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33726812",
   "metadata": {},
   "source": [
    "Finally, we can use `.loc[]` to insert rows in specific positions. If we want to insert a row between index 9802 and 9803, can set an index at some number in between (i.e. 9798.5) and add data using a dictionary. The key of the dictionary corresponds to the name of the column and the value corresponds to the data added in that column for the row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcfc4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.loc[9802.5] = {'Order ID': 'KB-2023-1849274', 'Order Date':'05/22/2023', \"Customer Name\": \"Kewon Bell\", \n",
    "                     \"Region\":\"Central\", \"City\":\"Chicago\", \"State\":\"Illinois\"}\n",
    "sales.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c8ee7a",
   "metadata": {},
   "source": [
    "Notice that for the columns that we did not specify, NaN was used. NaN stands for \"Not a Number\", which is used as a placeholder since we did not have any data for these columns. \n",
    "\n",
    "Now that we have our data added to the end of our dataframe, we can sort the indexes by using the `.sort_index()` method. When we call this method on our dataframe, we can set the `ascending` parameter equal to `False` to have our indexes go from largest to smallest. We can then set `inplace` equal to `True` so that it updates the dataframe without reassignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a5eed6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales.sort_index(ascending=False, inplace=True)\n",
    "sales.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00866c5b",
   "metadata": {},
   "source": [
    "The new row has been placed in between the 9803 index and 9802 index. This is the desired location that we wanted, however, we do not want an index as a float. To fix this, we can simply reset our indexes using `.reset_index()`. By setting `drop=True`, we get rid of the column that was once the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70931995",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales.reset_index(drop=True, inplace=True)\n",
    "sales.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbf2ad0",
   "metadata": {},
   "source": [
    "Our dataframe has now been sorted and reset. All of the rows that were at the end are now at the beginning.\n",
    "\n",
    "But say we made a mistake and we wanted to remove that row again, we could use the `.drop()` method again, but this time, use the `index` parameter and set it to the index of the row we want to remove. To update the dataframe you can use reassignment or set `inplace=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.drop(index=1, inplace=True)\n",
    "sales.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af692cd",
   "metadata": {},
   "source": [
    "So now we have the row we wanted removed, but we should still like to fix our `Row ID` column to make them integers again. We can do this using a method called `.astype()`. This method can be used to change the data type of a dataframe or series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73a6da3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales['Row ID'] = sales['Row ID'].astype(int)\n",
    "sales.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfc1dfb",
   "metadata": {},
   "source": [
    "Finally, we can set the indexes of our dataframe to any column within the dataframe by using `.set_index()`. The `.set_index()` method can be used to set unique identifiers, such as a user ID or social security number, as this index, which could be very useful for label-based selection.\n",
    "\n",
    "For now, we will use the `Row ID` column to set our indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c8d459",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales.set_index('Row ID', inplace=True)\n",
    "sales.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f16cebf",
   "metadata": {},
   "source": [
    "### <code style=\"background:#83ebd5;color:black\">Exercise:</code>\n",
    "\n",
    "- The `Zip Code` column of `sales`, for some odd reason, is recorded as floats. Convert this column to integers.\n",
    "\n",
    "- From `sales`, select all entries from Southwestern states (Arizona, New Mexico, Texas, Oklahoma) that ordered products from the `Art` sub-category. Assign this dataframe as `southwest`. *Hint: this may require an intermediate step.*\n",
    "\n",
    "- From `sales`, select the `Customer ID`, `Customer Name`, `Segment`, and `Sales` columns. Assign this dataframe as `customers`. Then, set the index of `customers` to be the `Customer ID` column. Using the index, select orders with the customer ID <u>SH-19975</u>. *Hint: refer to the `pandas.DataFrame.loc` online documentation if you get stuck.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdb0945",
   "metadata": {},
   "source": [
    "## Organizing, manipulating, analyzing data in dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d855d2",
   "metadata": {},
   "source": [
    "There are many functions and methods that can assist with organizing, manipulating, and analyzing data in dataframes. We will discuss several important ones to remember.\n",
    "\n",
    "The first method we will discuss is the `.sort_values()` method. This is a useful method for looking at trends or sequential values in a dataset. The `.sort_values()` method has an `ascending` parameter, which is set to `True` by default. It also has an `inplace` parameter, which is set to `False` by default: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d665a83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales.sort_values('City', inplace= True)\n",
    "sales.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f8c6d2",
   "metadata": {},
   "source": [
    "Another useful method is the \n",
    "`.value_counts()` method. This method can be used on a series to count the number of occurences for each unique value in the series. Let's use this method to determine how many shipments were shipped to each region:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e5d629",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Region'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba004c67",
   "metadata": {},
   "source": [
    "There are a number of statistical and summative methods that can be used on dataframes as well. For example, the `.min()` and `.max()` methods can be used on a a dataframe or a column within a dataframe to determine the minimum and maximum values, respectively. The `.describe()` method returns multiple useful summary statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845e9831",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Sales'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaa5672",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Sales'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b0e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Sales'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc305b6",
   "metadata": {},
   "source": [
    "Here's a short list of methods that can be used to determine summative information and/or statistics:\n",
    "\n",
    "`.min()` - determines the minimum value in a dataframe/series\n",
    "\n",
    "`.max()` - determines the maximum value in a dataframe/series\n",
    "\n",
    "`.mean()` - determines the mean value of a dataframe/series\n",
    "\n",
    "`.median()` - determines the median value in a dataframe/series\n",
    "\n",
    "`.sum()` - determines the sum of the values in a dataframe/series\n",
    "\n",
    "`.mode()` - determines the mode of a dataframe/series\n",
    "\n",
    "`.nlargest()` - determines the largest *n* items in a series. (Default = 5)\n",
    "\n",
    "`.nsmallest()` - determines the smallest *n* items in a series. (Default = 5)\n",
    "\n",
    "`.count()` - counts all non-null items in a dataframe/series\n",
    "\n",
    "`.value_counts` - counts the number of times an item occurs in a dataframe/series\n",
    "\n",
    "`.nunique()` - counts the number of unique items in a dataframe/series\n",
    "\n",
    "`.unique()` - lists all of the unique items in a dataframe/series\n",
    "\n",
    "`.describe` - generates descriptive statistics of a dataframe column, including those that summarize the central tendency, dispersion and shape of a dataset’s distribution, excluding null values (NaN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76df4a80",
   "metadata": {},
   "source": [
    "Sometimes when working with data, especially data generated by human input, we encounter errors within the data. One useful tool that can be used to find mistakes is the `.duplicated()` method. This method shows duplicated rows within a dataframe, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6255e4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[sales.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe580c49",
   "metadata": {},
   "source": [
    "When `.duplicated()` is called on a dataframe, another dataframe containing the rows of the duplicated entries is returned to us. We can easily get rid of these duplicated rows by calling `.drop_duplicates()` on the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a2602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sales.shape)\n",
    "sales = sales.drop_duplicates()\n",
    "print(sales.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13b37fc",
   "metadata": {},
   "source": [
    "We see that prior to dropping the duplicates, `sales` had 9804 rows. After dropping the duplicates, there are now 9799 rows, 5 less than before. This is the number of rows that were determined to be duplicated in `sales`, as shown above.\n",
    "\n",
    "We can also correct typos observed in dataframes. Say for example, we had a customer listed in our dataframe as Eric Hoffmann. We can extract all the rows pertaining to this customer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8f3665",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales.loc[(sales['Customer Name']) == 'Eric Hoffmann'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d75333e",
   "metadata": {},
   "source": [
    "Say an extra 'n' was accidentally added to Eric's last name. We can correct this typo in all of these cells by using the `.replace()` method. When using the `.replace()` method, we can call the current mispelling into the `to_replace` parameter. We can then call the correct spelling into the `value` parameter. The `inplace` parameter will update our dataframe in real time. \n",
    "\n",
    "If we try to extract rows with the original spelling, we get an empty dataframe returned to us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b035f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[\"Customer Name\"].replace(to_replace='Eric Hoffmann', value='Eric Hoffman', inplace=True)\n",
    "\n",
    "sales.loc[(sales['Customer Name']) == 'Eric Hoffmann'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c2b6fa",
   "metadata": {},
   "source": [
    "If we use the new spelling, we can see that the name has been updated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f855d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.loc[(sales['Customer Name']) == 'Eric Hoffman'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355edfca",
   "metadata": {},
   "source": [
    "We can also apply string methods to columns in a dataframe and update the column through variable assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a4ebbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales['State'] = sales['State'].str.upper()\n",
    "sales.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8f7109",
   "metadata": {},
   "source": [
    "Another useful method is the `.map()` method. The `.map()` method substitutes values from a series, dictionary, or function based on current values in the dataframe. Using this method, we can map the values in the `Shipping Method` column to their corresponding string values like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fc5089",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_vals = {0: 'Same Day', 1: 'First Class', 2:'Second Class', 3:'Standard Class'}\n",
    "\n",
    "sales['Shipping Method'] = sales['Shipping Method'].map(new_vals)\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5e647c",
   "metadata": {},
   "source": [
    "Applying values and functions en masse to datasets is a quick and easy way to analyze and modify data. The `.applymap()` method is great for this because uses a function and applies it to an entire dataframe. Say we wanted to convert all the data in sales to string data, we would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaf1d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = sales.applymap(str)\n",
    "strings.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30948ae4",
   "metadata": {},
   "source": [
    "By eye, `strings` looks the same as `sales`, but upon closer investigation, we can see that the numbers have been converted to strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8d1ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings['Zip Code'][5] #Picking a random number from the Zip Code column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e474e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(strings['Zip Code'][5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b00046b",
   "metadata": {},
   "source": [
    "The `.apply()` method is also great for applying a function to a series or multiple columns within a dataframe across an axis (i.e. across rows or across columns). For example, if we wanted to count the characters in each state for each row, we could apply the `len` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe323aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sales['State'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50cd383",
   "metadata": {},
   "source": [
    "When using the`.apply()` method on multiple columns of a dataframe, the`axis` parameter dictates if you function is applied acrossed rows or columns. When `axis=0`, the function is applied across columns, and when `axis=1`, the function is applied across rows.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/campbelle1/CAN2023/4c78054e6a24add10344d95ab609c1ecba3d6999/apply-method.png\" width=\"600\"/>\n",
    "\n",
    "Apply can be useful for aggregate functions, such as `np.min`, `np.max`, `np.mean`, and `np.sum`. For more information, refer to the `.apply()` method documentaion in the `pandas`. You will see other applications of `.apply()` when learning how to make user-defined functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c07faf",
   "metadata": {},
   "source": [
    "# Activity\n",
    "\n",
    "A study including 1040 subjects examines the effects of a weight loss medication. The study records subject demographics, such as age and sex, as well as each subject's weight for seven days. Each subject was assigned a unique identification number.\n",
    "\n",
    "- Load the data from the provided internet URL. Assign this data to a dataframe called `study`.\n",
    "\n",
    "- The downloaded data file did not include data from the last two subjects. Using the following information, append this data to `study`:\n",
    "<img align=\"center\" src=\"https://raw.githubusercontent.com/campbelle1/CAN2023/161d2a06dfe210825ea764fb65d0c5cfdcdd51a7/Extras.png\" width=\"20%\"/> \n",
    "\n",
    "- From `study`, determine the minimum and maxmimum weights for each subject within the seven day period of the experiment. Append this information as new columns called `Min Weight` and `Max Weight` in the `study` dataframe.\n",
    "\n",
    "- Find the net weight change from the beginning of the experiment to the end of the experiment for each subject.\n",
    "\n",
    "- For the ease of data collection, treatments for the study were recorded as 0 (to mean the subject received the placebo) or 1 (to mean the subject received the weight loss medication). Replace these integers with the description of the treatment (that is, *Placebo* or *Medication*).\n",
    "\n",
    "- Researchers have seen anecdotally that older subjects seem to lose more weight than younger subjects. Determine the top 10% of subjects that had the most weight loss. Calculate the proportion of subjects in the top 10% that were over the age of 35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681c376d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
